{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import text_processor as tp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load('en', parse=True, tag=True, entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/amazon/tfidf.pickle', 'rb') as data:\n",
    "    tfidf = pickle.load(data)\n",
    "\n",
    "with open('pickles/amazon/mnb_classifier.pickle', 'rb') as data:\n",
    "    mnb_model = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"item stopped working after 2 months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love the color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"it would not load my books proper. took a dozen tries erasing an dreregistering. screen too dark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Everything is great except that i can't read external pdfs properly. Either it zooms too much of too little. For kindle books it provides great experience. Battery life is awesome!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = tp.clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(cleaned_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf.transform([cleaned_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "category_id = mnb_model.predict(tfidf_vector)\n",
    "print(category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_sorting = np.argsort(tfidf_vector.toarray()).flatten()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = feature_array[tfidf_sorting][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['load' 'try' 'book' 'take' 'screen' 'would' 'fit' 'feature' 'feel' 'find'\n",
      " 'fine']\n"
     ]
    }
   ],
   "source": [
    "print(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['book', 'take', 'dozen', 'erase', 'dark'],\n",
       " ['proper', 'screen'],\n",
       " ['load', 'try', 'dreregistering'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_tags(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top(text, tfidf_vector):\n",
    "    feature_array = np.array(tfidf.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(tfidf_vector.toarray()).flatten()[::-1]\n",
    "    n=5\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(text):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)    \n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    verbs = []\n",
    "    for word, tag in pos_tags:\n",
    "        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\":\n",
    "            nouns.append(word)\n",
    "        elif tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n",
    "            verbs.append(word)\n",
    "        elif tag == \"JJ\" or tag == \"JJR\" or tag == \"JJS\" or tag == \"RB\" or tag == \"RBR\" or tag == \"RBS\":\n",
    "            adjectives.append(word)\n",
    "    return nouns, adjectives, verbs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Item stopped working after 2 months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns, adjectives, verbs = get_pos_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Everything', 'i', 'pdfs', 'properly.', 'Either', 'books', 'Battery', 'life']\n",
      "['great', 'read', 'external', 'too', 'much', 'too', 'little.', 'kindle', 'great', 'experience.', 'awesome']\n",
      "['is', 't', 'zooms', 'provides', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(nouns)\n",
    "print(adjectives)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cause of positivity: Everything\n",
      "Positive word: great\n"
     ]
    }
   ],
   "source": [
    "print(f'Cause of positivity: {nouns[0]}') \n",
    "print(f'Positive word: {adjectives[0] if adjectives else verbs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = find_top(text, tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['itemstop workstopmonth']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "['item' 'stop work' 'stop' 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Everything is great except that i can't read external pdfs properly. Either it zooms too much of too little. For kindle books it provides great experience. Battery life is awesome!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It's beyond my expectation, and it can even show music score. Not fast turning though.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"the stocks fell quickly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"very good color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'stocks', 'fell', 'quickly']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('stocks', 'NNS'), ('fell', 'VBD'), ('quickly', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    pos_tag = nltk.pos_tag(text.split())\n",
    "    pos_tagged_noun_verb = []\n",
    "    for word,tag in pos_tag:\n",
    "        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\" or tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n",
    "            pos_tagged_noun_verb.append(word + '_' + tag)\n",
    "    return pos_tagged_noun_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love_VBP', 'color_NN']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -PRON- PRON PRP\n",
      "\n",
      "love love VERB VBP\n",
      "\n",
      "the the DET DT\n",
      "\n",
      "color color NOUN NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in text:\n",
    "    print(word,word.lemma_, word.pos_, word.tag_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([(word.lemma_+'_'+word.tag_) if word.lemma_ != '-PRON-' else (word.text+'_'+word.tag_) for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_PRP love_VBP the_DT color_NN\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
